# Live Stream Chat AI Agent Backend Configuration (.env.example)
# Copy this file to .env and fill in your actual values.
# Lines starting with # are comments.

# INFERENCE_SERVICE_API_KEY
# The API key used to authenticate communications between the frontend worker (e.g., a Tampermonkey script) and the backend inference service.
# All requests made to the inference service must include this key in the 'X-Api-Key' header to ensure the request is legitimate and secure, preventing unauthorized API access.
INFERENCE_SERVICE_API_KEY="a-secret-key-between-worker-and-inference"

# --- Core Server Settings ---
# SERVER_HOST: IP address to bind the server to.
#   '0.0.0.0' makes it accessible from other machines on the network.
#   '127.0.0.1' restricts access to the local machine only.
SERVER_HOST=127.0.0.1

# SERVER_PORT: Port number the server will listen on.
SERVER_PORT=8181

# SERVER_ENABLE_SSL: Enable HTTPS. Set to 'true' to enable, 'false' to disable (HTTP).
# If true, SSL_CERT_PATH and SSL_KEY_PATH must be valid.
SERVER_ENABLE_SSL=true

# SSL_CERT_PATH: Absolute or relative path to your SSL certificate file (e.g., fullchain.pem).
# Required if SERVER_ENABLE_SSL is true.
# Example: /etc/letsencrypt/live/yourdomain.com/fullchain.pem
SSL_CERT_PATH=

# SSL_KEY_PATH: Absolute or relative path to your SSL private key file (e.g., privkey.pem).
# Required if SERVER_ENABLE_SSL is true.
# Example: /etc/letsencrypt/live/yourdomain.com/privkey.pem
SSL_KEY_PATH=

# SERVER_TEST_MODE: Save incoming audio/screenshot and processing info for debugging.
# Set to 'true' to enable, 'false' to disable. Recommended: false for production.
SERVER_TEST_MODE=false

# --- LLM (Language Model) Configuration ---
# Supported values (case-insensitive):
# - openai: Official OpenAI API (https://platform.openai.com)
# - azure: Azure OpenAI Service (requires Azure-specific endpoint)
# - api2d: API2D OpenAI-compatible proxy (https://api2d.com)
# - openrouter: OpenRouter aggregator (supports Claude/Gemini etc.) - https://openrouter.ai
# - claude: Anthropic Claude models (https://www.anthropic.com)
# - gemini: Google Gemini models (https://aistudio.google.com/app/apikey)
# - deepseek: DeepSeek developer platform (China-based GPT-style models) - https://platform.deepseek.com
# - groq: Groq ultra-fast model API (supports LLaMA3 etc.) - https://console.groq.com
# - other: Any other OpenAI-compatible/self-hosted service (e.g., LM Studio)
LLM_PROVIDER=

# LLM_API_KEY: Your API key for the OpenAI-compatible service. (REQUIRED)
LLM_API_KEY=

# LLM_API_URL: The base URL of the OpenAI-compatible API endpoint. (REQUIRED)
# Example for OpenAI: https://api.openai.com/v1
# Example for local LM Studio: http://localhost:1234/v1
LLM_API_URL=https://api.openai.com/v1

# LLM_API_MODEL: The model identifier to use for chat completions (e.g., gpt-4o, gpt-4.5).
# Recommended model: claude-3-7-sonnet-20250219
LLM_API_MODEL=

# LLM_TOKENIZER_MODEL: The model name used *specifically* for calculating token counts with tiktoken.
# Often the same as LLM_API_MODEL, but sometimes a base model like 'gpt-4' works better for token estimation across variants.
# If you're not sure and your model is not in the tokenizer support list, you can try using gpt-4 or gpt-4o.
LLM_TOKENIZER_MODEL=gpt-4o

# LLM_MAX_RESPONSE_TOKENS: Maximum number of tokens the LLM is allowed to generate in a single response.
LLM_MAX_RESPONSE_TOKENS=2000

# LLM_API_TIMEOUT_SECONDS: Timeout duration (in seconds) for waiting for a response from the LLM API.
LLM_API_TIMEOUT_SECONDS=60

# LLM_OPTIMIZE_TIMEOUT_SECONDS: Specific timeout duration (in seconds) for potentially longer-running LLM optimization tasks (e.g., notepad optimization). This typically overrides the default timeout for those specific operations.
LLM_OPTIMIZE_TIMEOUT_SECONDS=180

# Maximum tokens the LLM can generate specifically for notepad optimization
# Set this high, but potentially slightly less than the model's absolute max output limit
LLM_MAX_OPTIMIZE_RESP_TOKENS=8192

# --- Token Limits for Prompt Construction ---
# These control how much context (history, notepad, chat) is included in the prompt sent to the LLM.
# Tune these based on your LLM's context window size and cost considerations.

# PROMPT_MAX_TOTAL_TOKENS: The absolute maximum number of tokens allowed in the *entire* prompt + expected response buffer.
# This should be less than your model's context window limit (e.g., 4096, 8192, 128000).
# Includes system prompt, history, notepad, chat list, current input, and leaves space for the response.
PROMPT_MAX_TOTAL_TOKENS=4096

# PROMPT_MAX_NOTEPAD_TOKENS: Maximum tokens allocated for the {notepad: ...} section within the prompt.
PROMPT_MAX_NOTEPAD_TOKENS=2048

# PROMPT_MAX_CHATLIST_TOKENS: Maximum tokens allowed for the {Chatlist content: ...} block when building the user's input message for this round.
PROMPT_MAX_CHATLIST_TOKENS=256

# --- Notepad Auto Optimization ---
# Enable automatic background optimization when notepad exceeds threshold (true/false)
NOTEPAD_AUTO_OPTIMIZE_ENABLE=true

# Token threshold for triggering automatic notepad optimization (Must be > PROMPT_MAX_NOTEPAD_TOKENS)
NOTEPAD_AUTO_OPTIMIZE_THRESHOLD_TOKENS=2049

# --- Speech-to-Text (STT) Configuration ---
# STT_PROVIDER: Choose the preferred STT service. Options: 'youdao', 'whisper', 'both'.
#   'youdao': Use Youdao ASR (requires YOUDAO_* keys). Good for Chinese.
#   'whisper': Use Whisper via the LLM_API_URL endpoint (requires LLM_API_KEY). Good multilingual support.
#   'both': Use both and include both results in the prompt.
#   'compare': (Special mode set via command line, not here) Runs both but doesn't call LLM.
STT_PROVIDER=youdao

# YOUDAO_APP_KEY: Your Youdao Application Key (required if STT_PROVIDER includes 'youdao').
YOUDAO_APP_KEY=

# YOUDAO_APP_SECRET: Your Youdao Application Secret (required if STT_PROVIDER includes 'youdao').
YOUDAO_APP_SECRET=

# YOUDAO_API_URL: Youdao ASR API endpoint URL. (Default is usually fine).
YOUDAO_API_URL=https://openapi.youdao.com/asrapi

# --- Whisper Speech-to-Text (STT) Configuration ---
# API endpoint URL for Whisper model.
# Example (OpenAI official): https://api.openai.com/v1/audio/transcriptions
# Example (self-hosted like whisper.cpp): http://localhost:9000/v1/audio/transcriptions
WHISPER_API_URL=

# API Key for Whisper access.
# Required for OpenAI official; usually leave empty for local deployments.
WHISPER_API_KEY=

# --- Vision / Screenshot Settings ---
# VISION_ENABLE: Enable processing of screenshots. Set to 'true' to enable, 'false' to disable.
# If true, Cloudinary settings might be required depending on VISION_UPLOAD_PROVIDER.
VISION_ENABLE=false

# VISION_UPLOAD_PROVIDER: Where to upload screenshots. Options: 'cloudinary', 'none'.
#   'cloudinary': Upload to Cloudinary (Requires CLOUDINARY_* settings). Image URL is sent to LLM.
#   'none': Screenshots are received but not uploaded or sent to the LLM (useful for local testing/saving).
VISION_UPLOAD_PROVIDER=cloudinary

# CLOUDINARY_CLOUD_NAME: Your Cloudinary cloud name (required if VISION_UPLOAD_PROVIDER='cloudinary').
CLOUDINARY_CLOUD_NAME=

# CLOUDINARY_API_KEY: Your Cloudinary API key (required if VISION_UPLOAD_PROVIDER='cloudinary').
CLOUDINARY_API_KEY=

# CLOUDINARY_API_SECRET: Your Cloudinary API secret (required if VISION_UPLOAD_PROVIDER='cloudinary').
CLOUDINARY_API_SECRET=

# CLOUDINARY_UPLOAD_FOLDER: Folder name on Cloudinary to store uploaded screenshots.
CLOUDINARY_UPLOAD_FOLDER=live_screenshot

# IMAGE_COMPRESSION_QUALITY: JPEG quality for compressing screenshots before upload (1-95). Lower means smaller file, lower quality.
# Set to 0 or > 95 to disable compression (uploads original PNG/JPG).
IMAGE_COMPRESSION_QUALITY=60

# --- System Prompt Configuration ---
# SYSTEM_PROMPT_MODE: How the system prompt is handled. Options: 'standard', 'user_message_compatibility'.
#   'standard': Send prompt using the 'system' role (Recommended for most models).
#   'user_message_compatibility': Send the system prompt as the *first* 'user' message (for models that don't support the system role well).
SYSTEM_PROMPT_MODE=standard

# SYSTEM_PROMPT_PATH: Path to a file containing the system prompt text. UTF-8 encoding is expected.
# If empty or file not found, a built-in default prompt will be used.
# Example: ./prompts/system_prompt_龟背竹.txt
SYSTEM_PROMPT_PATH=

# --- File Paths and Prefixes ---
# MEMORY_BASE_DIR: Directory where persistent data (notepad, context) for each room is stored.
MEMORY_BASE_DIR=memory

# TEST_FILES_DIR: Directory where files are saved when SERVER_TEST_MODE is true.
TEST_FILES_DIR=test

# AUDIO_TEMP_PREFIX: Prefix for temporary audio files created during processing.
AUDIO_TEMP_PREFIX=live_audio_

# SCREENSHOT_TEMP_PREFIX: Prefix for temporary screenshot files created during processing.
SCREENSHOT_TEMP_PREFIX=live_screenshot_

# FFMPEG_PATH: Path to the FFmpeg executable. Used for audio conversion (e.g., for Youdao).
# If ffmpeg is in your system's PATH, just 'ffmpeg' is usually sufficient.
FFMPEG_PATH=ffmpeg

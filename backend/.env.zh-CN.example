# 实时弹幕聊天 AI 代理 后端配置 (.env.zh-CN.example)
# 将此文件复制为 .env 并填写实际值。
# # 开头的行是注释。

# INFERENCE_SERVICE_API_KEY
# 用于验证前端 Worker (例如 Tampermonkey 脚本) 与后端推理服务之间通信的 API 密钥。
# 所有向推理服务发出的请求，都必须在请求标头 (Header) 的 'X-Api-Key' 字段中包含此密钥，以确保请求的合法性与安全性，防止未经授权的 API 访问。
INFERENCE_SERVICE_API_KEY="a-secret-key-between-worker-and-inference"

# --- 核心服务器设置 ---
# SERVER_HOST：服务器监听的 IP 地址。
#   '0.0.0.0' 表示可被网络上其他机器访问。
#   '127.0.0.1' 表示仅限本机访问。
SERVER_HOST=127.0.0.1

# SERVER_PORT：服务器监听的端口号。
SERVER_PORT=8181

# SERVER_ENABLE_SSL：是否启用 HTTPS。设置为 'true' 启用，'false' 禁用（HTTP）。
# 若启用，必须确保 SSL_CERT_PATH 和 SSL_KEY_PATH 有效。
SERVER_ENABLE_SSL=true

# SSL_CERT_PATH：SSL 证书文件（例如 fullchain.pem）的绝对或相对路径。
# 当 SERVER_ENABLE_SSL=true 时必填。
# 示例：/etc/letsencrypt/live/yourdomain.com/fullchain.pem
SSL_CERT_PATH=

# SSL_KEY_PATH：SSL 私钥文件（例如 privkey.pem）的绝对或相对路径。
# 当 SERVER_ENABLE_SSL=true 时必填。
# 示例：/etc/letsencrypt/live/yourdomain.com/privkey.pem
SSL_KEY_PATH=

# SERVER_TEST_MODE：调试模式。设置为 'true' 时会保存接收到的音频/截图及处理信息，建议生产环境设为 false。
SERVER_TEST_MODE=false

# --- LLM（语言模型）配置 ---
# LLM_PROVIDER：选择使用的大语言模型服务商。
# 支持的选项如下（不区分大小写）：
# - openai：OpenAI 官方（https://platform.openai.com）
# - azure：Azure OpenAI 服务（需配置 Azure 专属 URL）
# - api2d：API2D（https://api2d.com，OpenAI 代理服务）
# - openrouter：OpenRouter 聚合平台（支持 Claude/Gemini 等，https://openrouter.ai）
# - claude：Anthropic Claude 模型（https://www.anthropic.com）
# - gemini：Google Gemini 模型（https://aistudio.google.com/app/apikey）
# - deepseek：DeepSeek 开发者平台（China GPT 类模型，https://platform.deepseek.com）
# - groq：Groq 极速模型平台（支持 LLaMA3 等，https://console.groq.com）
# - other：其他兼容 OpenAI API 的平台或自建服务（例如 LM Studio）
LLM_PROVIDER=

# LLM_API_KEY：OpenAI 兼容服务的 API 密钥。（必填）
LLM_API_KEY=

# LLM_API_URL：OpenAI 兼容 API 的基准 URL。（必填）
# 示例（OpenAI）：https://api.openai.com/v1
# 示例（本地 LM Studio）：http://localhost:1234/v1
LLM_API_URL=https://api.openai.com/v1

# LLM_API_MODEL：用于聊天补全的模型标识符（例如 gpt-4o、gpt-4.5）。
# 推荐使用 claude-3-7-sonnet-20250219
LLM_API_MODEL=

# LLM_TOKENIZER_MODEL：用于使用 tiktoken 计算 token 数量时的模型名称。
# 通常与 LLM_API_MODEL 相同，但有时使用基础模型（如 'gpt-4'）对不同变体的 token 估算更稳定。
# 如果你不确定，并且你的模型不在 tokenizer 支持列表里，你可以尝试使用 gpt-4 或 gpt-4o。
LLM_TOKENIZER_MODEL=gpt-4o

# LLM_MAX_RESPONSE_TOKENS：模型一次生成的最大响应 token 数量。
LLM_MAX_RESPONSE_TOKENS=2000

# LLM_API_TIMEOUT_SECONDS：调用 LLM API 的超时时长（秒）。
LLM_API_TIMEOUT_SECONDS=60

# LLM_OPTIMIZE_TIMEOUT_SECONDS：专门为可能耗时较长的 LLM 优化任务（例如记事本优化）设置的超时时长（秒）。这通常会在此类特定操作中覆盖默认的超时设置。
LLM_OPTIMIZE_TIMEOUT_SECONDS=180

# LLM 专为记事本优化而生成的最大 token
# 将此值设置为较高，但可能略小于模型的绝对最大输出限制
LLM_MAX_OPTIMIZE_RESP_TOKENS=8192

# --- 提示构建的 token 限制 ---
# 控制发送给 LLM 的上下文（历史、笔记、聊天列表）内容量，根据模型上下文窗口大小和成本进行调整。

# PROMPT_MAX_TOTAL_TOKENS：整体提示+响应缓冲区允许的最大 token 数量。
# 应小于模型上下文窗口大小（例如 4096、8192、128000）。
PROMPT_MAX_TOTAL_TOKENS=4096

# PROMPT_MAX_NOTEPAD_TOKENS：笔记（notepad）部分允许的最大 token 数量。
PROMPT_MAX_NOTEPAD_TOKENS=2048

# PROMPT_MAX_CHATLIST_TOKENS：构造每轮用户输入时，允许用于 {Chatlist content: ...} 区块的最大 token 数量。
PROMPT_MAX_CHATLIST_TOKENS=256

# --- Notepad 自动优化 ---
# 是否启用 Notepad 自动后台优化 (当超过阈值时)
NOTEPAD_AUTO_OPTIMIZE_ENABLE=true

# 触发自动 Notepad 优化的 Token 阈值 (必须大于 PROMPT_MAX_NOTEPAD_TOKENS)
NOTEPAD_AUTO_OPTIMIZE_THRESHOLD_TOKENS=2049

# --- 语音转文字（STT）配置 ---
# STT_PROVIDER：首选 STT 服务。选项：'youdao'、'whisper'、'both'。
#   'youdao'：使用有道 ASR（需 YOUDAO_* 秘钥），适合中文。
#   'whisper'：使用通过 LLM_API_URL 的 Whisper（需 LLM_API_KEY），多语言支持更好。
#   'both'：同时使用两者，并将两者结果都包含在提示中。
#   'compare'：通过命令行设置的特殊模式，只跑两者但不调用 LLM。
STT_PROVIDER=youdao

# YOUDAO_APP_KEY：有道应用的 App Key（当 STT_PROVIDER 包含 'youdao' 时必填）。
YOUDAO_APP_KEY=

# YOUDAO_APP_SECRET：有道应用的 App Secret（当 STT_PROVIDER 包含 'youdao' 时必填）。
YOUDAO_APP_SECRET=

# YOUDAO_API_URL：有道 ASR API 端点 URL。（通常默认即可）
YOUDAO_API_URL=https://openapi.youdao.com/asrapi

# --- Whisper语音识别 (STT) 配置 ---
# Whisper模型的API接口URL。
# 示例（使用OpenAI官方）: https://api.openai.com/v1/audio/transcriptions
# 示例（使用本地部署如whisper.cpp）: http://localhost:9000/v1/audio/transcriptions
WHISPER_API_URL=

# Whisper API访问密钥。
# OpenAI官方需要填写API Key；本地部署通常留空。
WHISPER_API_KEY=

# --- 视觉/截图设置 ---
# VISION_ENABLE：是否启用截图处理。设置为 'true' 启用，'false' 禁用。
VISION_ENABLE=false

# VISION_UPLOAD_PROVIDER：截图上传提供商。选项：'cloudinary'、'none'。
#   'cloudinary'：上传到 Cloudinary（需 CLOUDINARY_* 配置），并将图片 URL 发送给 LLM。
#   'none'：接收截图但不上传或发送给 LLM（适合本地调试）。
VISION_UPLOAD_PROVIDER=cloudinary

# CLOUDINARY_CLOUD_NAME：Cloudinary 云名（当 VISION_UPLOAD_PROVIDER='cloudinary' 时必填）。
CLOUDINARY_CLOUD_NAME=

# CLOUDINARY_API_KEY：Cloudinary API Key（当 VISION_UPLOAD_PROVIDER='cloudinary' 时必填）。
CLOUDINARY_API_KEY=

# CLOUDINARY_API_SECRET：Cloudinary API Secret（当 VISION_UPLOAD_PROVIDER='cloudinary' 时必填）。
CLOUDINARY_API_SECRET=

# CLOUDINARY_UPLOAD_FOLDER：在 Cloudinary 上存储截图的文件夹名称。
CLOUDINARY_UPLOAD_FOLDER=live_screenshot

# IMAGE_COMPRESSION_QUALITY：截图压缩为 JPEG 的质量（1-95）。值越低文件越小但质量越差。
# 设置为 0 或大于 95 可禁用压缩（保留原始 PNG/JPG）。
IMAGE_COMPRESSION_QUALITY=60

# --- 系统提示配置 ---
# SYSTEM_PROMPT_MODE：系统提示的发送方式。选项：'standard'、'user_message_compatibility'。
#   'standard'：使用 'system' 角色发送（大多数模型推荐）。
#   'user_message_compatibility'：将系统提示作为第一个 'user' 消息发送（适用于不能很好地支持系统角色的模型）。
SYSTEM_PROMPT_MODE=standard

# SYSTEM_PROMPT_PATH：包含系统提示文本的文件路径，需 UTF-8 编码。
# 若为空或文件不存在，将使用内置默认提示。
# 示例：./prompts/system_prompt_龟背竹.txt
SYSTEM_PROMPT_PATH=

# --- 文件路径与前缀 ---
# MEMORY_BASE_DIR：各房间持久化数据（笔记、上下文）的存储目录。
MEMORY_BASE_DIR=memory

# TEST_FILES_DIR：SERVER_TEST_MODE=true 时用于保存测试文件的目录。
TEST_FILES_DIR=test

# AUDIO_TEMP_PREFIX：临时音频文件前缀，用于处理中。
AUDIO_TEMP_PREFIX=live_audio_

# SCREENSHOT_TEMP_PREFIX：临时截图文件前缀，用于处理中。
SCREENSHOT_TEMP_PREFIX=live_screenshot_

# FFMPEG_PATH：FFmpeg 可执行文件路径，用于音频转换（如有道）。
# 若已添加到系统 PATH，只需写 'ffmpeg'。
FFMPEG_PATH=ffmpeg

